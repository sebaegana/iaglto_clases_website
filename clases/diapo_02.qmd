---
listing_title: "Diapositiva 02"
title: "IA Generativa y LLMs para la TransformaciÃ³n Organizacional"
subtitle: "FEN Unegocios"
institution: 'Lorem ipsum'
lang: es
date: today
format:
  revealjs:
    theme: simple
    slide-number: true
    self-contained: true
    incremental: true
    transition: slide
    logo: "imagenes/Imagen1.jpg"
    footer: "Â© SebastiÃ¡n EgaÃ±a SantibÃ¡Ã±ez"
    include-in-header: styles.html
  pdf:
    toc: false
    papersize: a4
    geometry: margin=1in
---

```{r load_packages, message=FALSE, warning=FALSE, include=FALSE}
library(fontawesome)
```

# Enlaces

-   `r fa("message", fill = "steelblue")` segana\@fen.uchile.cl
-   `r fa("computer", fill = "steelblue")` <https://segana.netlify.app>
-   `r fa("linkedin", fill = "steelblue")` <https://www.linkedin.com/in/sebastian-egana-santibanez/>
-   `r fa("github", fill = "steelblue")` <https://github.com/sebaegana>

---

# Clase 02

## Objetivo general

-   Analizar el rol de la inteligencia artificial generativa en la estrategia empresarial

---

## Pregunta activadora

**Â¿QuÃ© procesos de su organizaciÃ³n creen que podrÃ­an mejorar con IA generativa?**

![](imagenes/adoption_01.png){fig-align="center"}

# Â¿QuÃ© es (y quÃ© no es) Inteligencia Artificial?

-   **IA:** capacidad de sistemas para aprender patrones y tomar decisiones basadas en datos
-   **No es:** magia ni conciencia, sino algoritmos que **aprenden de ejemplos**\
-   Se basa en **estadÃ­stica, aprendizaje automÃ¡tico y automatizaciÃ³n**

---

![Recuperado en: https://www.orsys.fr/orsys-lemag/es/aprendizaje-automatico-aprendizaje-profundo-ia-diferencias](imagenes/ia_ml.png)

---

# Â¿QuÃ© es la IA Generativa? 

## Conceptos fundamentales 

- **IA (Artificial Intelligence):** mÃ¡quinas que realizan tareas que suelen requerir inteligencia humana.  
- **IA Generativa:** sistemas capaces de *crear* contenido como lo hacemos los humanos (texto, imÃ¡genes, audio, cÃ³digo).

- Idea central: La IA generativa predice patrones para producir contenido original.

- IA y algoritmos: Algoritmos como serie de reglas dadas; en el caso de la IA esos algoritmos son construidos por la IA y puede ser mejorados. 

---

## Innovaciones clave en la historia

::: columns
::: column

::: tiny
1. **Cloud computing** â†’ datos + cÃ³mputo  
2. **GANs** â†’ imÃ¡genes fotorrealistas â†’ [Ver enlace](https://thispersondoesnotexist.com)
3. **Transformers** â†’ comprensiÃ³n profunda del lenguaje â†’ [Ver enlace](https://arxiv.org/abs/1706.03762) 
4. **RLHF** â†’ modelos afinados con retroalimentaciÃ³n humana  
5. **Midjourney / Stable Diffusion / GPT-4** â†’ multimodalidad y creatividad avanzada
:::
:::

::: column
![Recuperado de: Curso *Generative AI for Business*, DataCamp](imagenes/line_events.png){width="60%"}
:::
:::

---

## Para revisar

```{r}
#| echo: false
#| message: false
#| warning: false
#| results: 'asis'

library(rvest)
library(dplyr)
library(glue)

url <- "https://education.illinois.edu/about/news-events/news/article/2024/11/11/what-is-generative-ai-vs-ai"

page <- read_html(url)

title <- page %>%
  html_element("meta[property='og:title']") %>%
  html_attr("content")

description <- page %>%
  html_element("meta[property='og:description'], meta[name='description']") %>%
  html_attr("content")

cat(glue('
::: {{.callout-note}}
## {title}

{description}

[Leer nota completa]({url})
:::
'))
```

---

## ğŸ¤– La IA no es un modelo â€” es un ecosistema de componentes

Un **LLM** (Large Language Model) como GPT o Claude es solo una parte del sistema.

Para responder una consulta compleja, se articulan **varios segmentos de IA**:

::: tiny
-   **Computer Vision** â†’ detecta y analiza imÃ¡genes (objetos, rostros, escenas).\
-   **OCR (Reconocimiento Ã“ptico de Caracteres)** â†’ extrae texto de imÃ¡genes o PDFs.\
-   **Speech Recognition / TTS** â†’ convierte audio en texto y viceversa.\
-   **LLM** â†’ interpreta, contextualiza y genera una respuesta en lenguaje natural.\
-   **Reasoning / Orchestration Layer** â†’ decide quÃ© componentes usar y en quÃ© orden.
:::

---

::: {=html}
```{=html}
<pre style="font-size:1em; line-height:1;">
ğŸ“· Imagen â”€â”€â–¶ ğŸ§  Computer Vision
â€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ”‚
â€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ–¼
â€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒğŸ§¾ OCR (Texto extraÃ­do)
â€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ”‚
â€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ–¼
â€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒğŸ’¬ LLM (ComprensiÃ³n y respuesta)
â€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ”‚
â€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ–¼
â€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒğŸ§­ Respuesta contextual en lenguaje natural
</pre>
```
:::

-   Resultado: â€œEl documento corresponde a un contrato de servicios con fecha de inicio 2024-01-10 entre X y Y.â€

---

## Â¿QuÃ© es un LLM? (Large Language Model)

Un **LLM (Large Language Model)** es un modelo de inteligencia artificial entrenado con **enormes cantidades de texto** para:

- predecir la siguiente palabra 
- generar respuestas coherentes  
- comprender contextos complejos  
- producir contenido (texto, cÃ³digo, instrucciones)  
- razonar de manera estadÃ­stica

---

### Idea clave

Un LLM **no entiende**, sino que **modela patrones del lenguaje** para generar la respuesta mÃ¡s probable segÃºn los datos con los que fue entrenado.

### Â¿CÃ³mo procesan texto los LLMs?

Los modelos de lenguaje procesan texto mediante una serie de pasos y **parÃ¡metros clave** que controlan cÃ³mo entienden, representan y generan lenguaje.

---

### ParÃ¡metros internos del modelo (no ajustables por el usuario)

:::tiny
Son parte de la arquitectura del LLM y definen cÃ³mo representa y procesa lenguaje.

- embedding dimension (p. ej. 768, 1536, 4096â€¦)
- tokenizer (reglas que dividen el texto)
- context window (mÃ¡ximo de tokens simultÃ¡neos)
- nÃºmero de capas (layers)
- nÃºmero de cabezas de atenciÃ³n (attention heads)
- matrices de atenciÃ³n
- parÃ¡metros totales del modelo (ej. 8B, 70B, 1T)
:::

---

#### Tokens

Los LLMs no leen palabras completas: dividen el texto en **tokens**, que pueden ser:

- sÃ­labas
- fragmentos de palabra
- palabras completas (si son comunes)
- signos de puntuaciÃ³n

---

**Ejemplos:** â€œinteligenciaâ€ â†’ â€œinâ€, â€œtelâ€, â€œigenâ€, â€œciaâ€

**Claves:**

- MÃ¡s tokens â†’ mÃ¡s costo computacional  
- Todos los modelos operan en *token space*, no en texto literal  
- Todo input y output se mide en tokens

---

#### Embeddings

Cada token se transforma en un **vector numÃ©rico** en un espacio de cientos o miles de dimensiones.

Esto permite que el modelo codifique:

- significado  
- contexto  
- relaciones semÃ¡nticas  
- similitud entre conceptos

**Los embeddings son el â€œidioma internoâ€ del modelo.**

---

##### Sobre los embeddings

###### Entrenamiento previo de los embeddings

Los embeddings que usamos (por ejemplo, con OpenAI o modelos open source) no se crean desde cero cada vez que los aplicamos. En realidad, provienen de un proceso de entrenamiento previo (pre-training) realizado sobre enormes cantidades de texto.

```{r}
#| echo: false
#| message: false
#| warning: false
#| results: 'asis'

library(rvest)
library(dplyr)
library(glue)

url <- "https://huggingface.co/blog/getting-started-with-embeddings"

page <- read_html(url)

title <- page %>%
  html_element("meta[property='og:title']") %>%
  html_attr("content")

description <- page %>%
  html_element("meta[property='og:description'], meta[name='description']") %>%
  html_attr("content")

cat(glue('
::: {{.callout-note}}
## {title}

{description}

[Leer nota completa]({url})
:::
'))
```

---

##### Â¿QuÃ© aprende el modelo?

:::tiny

Durante el entrenamiento, el modelo analiza millones o miles de millones de frases y aprende relaciones estadÃ­sticas entre palabras. El objetivo es que, al ver una secuencia de texto, el modelo pueda predecir la siguiente palabra o reconocer palabras que encajan en el mismo contexto.

| Texto de entrenamiento | Tarea implÃ­cita | Lo que aprende |
|-------------------|------------------------|------------------------------|
| â€œEl **perro** ladra en el jardÃ­n.â€ | Predecir â€œperroâ€ a partir de su contexto (â€œEl â€¦ ladraâ€¦â€) | Que â€œperroâ€ aparece en contextos parecidos a â€œgatoâ€, â€œanimalâ€, â€œmascotaâ€. |
| â€œEl **aviÃ³n** aterriza en la pista.â€ | Predecir â€œaviÃ³nâ€ | Que â€œaviÃ³nâ€ se asocia a â€œvueloâ€, â€œpilotoâ€, â€œaeropuertoâ€. |

AsÃ­, el modelo descubre automÃ¡ticamente los significados y las similitudes semÃ¡nticas sin reglas escritas por humanos.

:::

---

##### Â¿QuÃ© produce este aprendizaje?

El modelo transforma cada palabra (o token) en un vector numÃ©rico que resume su significado aprendido. Estos vectores viven en un espacio de alta dimensiÃ³n (por ejemplo, 768 o 1536 dimensiones). En ese espacio, las palabras que comparten contexto quedan cerca entre sÃ­, y las que no tienen relaciÃ³n quedan lejos.

---

Ejemplo esquemÃ¡tico (espacio 2D simplificado):

Imaginemos que tenemos solo dos dimensiones (en realidad hay miles). Cada palabra se convierte en un punto:

| Palabra | Eje X (animalidad) | Eje Y (domesticidad) |
|---------|--------------------|----------------------|
| gato    | 0.9                | 0.95                 |
| perro   | 0.85               | 0.97                 |
| lobo    | 0.88               | 0.30                 |
| aviÃ³n   | 0.10               | 0.05                 |

---

En el grÃ¡fico:

![](imagenes/embedding_plot.png){width="50%" fig-align="center"}

:::tiny

  - gato y perro estÃ¡n muy cerca, porque comparten significado.
  - lobo estÃ¡ un poco mÃ¡s lejos: sigue siendo animal, pero no domÃ©stico.
  - aviÃ³n estÃ¡ totalmente fuera del grupo

:::


---

##### Un ejemplo en python:

:::tiny
InstalaciÃ³n de librerÃ­as:

``` python
pip install openai numpy faiss-cpu
```

GeneraciÃ³n de embeds

``` python
from openai import OpenAI
import numpy as np
import faiss  # base de datos vectorial
client = OpenAI()

# Textos a convertir en embeddings
sentences = [
    "The dog is barking.",
    "A cat is sleeping on the couch.",
    "A car is driving down the street.",
    "I love my pet animal."
]

# Crear embeddings usando el modelo de OpenAI
response = client.embeddings.create(
    model="text-embedding-3-small",
    input=sentences
)

# Extraer los vectores
vectors = np.array([data.embedding for data in response.data])
print("DimensiÃ³n de los embeddings:", vectors.shape)
```
:::

----

Salida esperada:

:::tiny

``` yaml
DimensiÃ³n de los embeddings: (4, 1536)
```

``` python
# Crear un Ã­ndice FAISS
index = faiss.IndexFlatL2(vectors.shape[1])
index.add(vectors)

# Consultar algo nuevo
query = "My puppy is barking loudly."
query_vec = client.embeddings.create(
    model="text-embedding-3-small",
    input=query
).data[0].embedding

# Buscar el texto mÃ¡s parecido
D, I = index.search(np.array([query_vec]), k=2)
print("Resultados similares:")
for idx in I[0]:
    print("-", sentences[idx])
```
:::

Resultados similares:

  -   The dog is barking.
  -   I love my pet animal.

---

### ParÃ¡metros de entrenamiento (cÃ³mo se entrenan los modelos)

Estos parÃ¡metros son importantes para entender el â€œpor quÃ©â€ del desempeÃ±o de un LLM.

---

#### TamaÃ±o del modelo (nÃºmero de parÃ¡metros)
Los â€œparÃ¡metrosâ€ son los pesos internos del modelo (similares a neuronas).

- Llama 3: 8Bâ€“70B  
- GPT-3: 175B  
- GPT-4 real: desconocido (estimado entre 800B y 1.8T)  
- Claude 3 Opus: no divulgado, estimado muy alto  

**MÃ¡s parÃ¡metros â‰  mejor siempre** 

Depende del entrenamiento, datos y arquitectura.

---

#### Embedding dimension

Cantidad de dimensiones en que se representan los vectores.

- Modelos pequeÃ±os: 512â€“2048  
- Modelos grandes: 4096â€“16384

Afecta:

- capacidad semÃ¡ntica  
- riqueza de representaciÃ³n  
- costo computacional

---

#### Batch size (en entrenamiento)

Cantidad de ejemplos procesados simultÃ¡neamente.

- batch grande â†’ aprendizaje mÃ¡s estable  
- batch pequeÃ±o â†’ aprendizaje mÃ¡s ruidoso

Esto afecta:

- calidad final  
- velocidad de entrenamiento  
- requerimientos de GPU

*(No confundir con â€œbatch sizeâ€ de inferencia en APIs.)*

---

#### Longitud del pre-training

Los modelos mejoran no solo por tamaÃ±o, sino por:

- mÃ¡s pasos de entrenamiento  
- mejores datos  
- mejores instrucciones  
- mejor RLHF

---

#### Ventana de contexto (context window)
Es la cantidad mÃ¡xima de tokens que el modelo puede considerar **al mismo tiempo**.

- GPT-4: ~128k  
- GPT-4o: ~200k  
- Claude 3 Opus: ~200k  
- Gemini 1.5 Ultra: ~1M  
- Llama 3: 8kâ€“128k (segÃºn versiÃ³n)

**MÃ¡s contexto = modelos con â€œmemoria a corto plazoâ€ mÃ¡s amplia.**

---

### ParÃ¡metros de generaciÃ³n (cÃ³mo controlamos la salida)

Estos parÃ¡metros **no afectan cÃ³mo el modelo entiende**, sino **cÃ³mo genera texto**. Son esenciales en prompt engineering.

---

#### Temperatura (temperature)

:::tiny
Controla la **aleatoriedad**.

- Temperatura baja (0.0â€“0.3):

  - mÃ¡s precisiÃ³n  
  - respuestas estables y deterministas
  
- Temperatura alta (0.7â€“1.2): 

  - mÃ¡s creatividad  
  - mÃ¡s variaciÃ³n  
  - mayor riesgo de errores

**Regla:**  

- anÃ¡lisis â†’ baja  
- creatividad â†’ alta
:::

---

#### Top-p (nucleus sampling)

Controla el **porcentaje de probabilidad acumulada** desde donde el modelo puede elegir la prÃ³xima palabra.

- top-p = 0.1 â†’ muy restrictivo  
- top-p = 0.9 â†’ muy diverso  
- top-p = 1.0 â†’ sin restricciones

**Usado junto a temperatura para ajustar estilo y creatividad.**

---

#### Top-k

LÃ­mite del nÃºmero de tokens candidatos que el modelo puede elegir.

- top-k = 1 â†’ modo determinista  
- top-k = 40 â†’ moderado  
- top-k = 100+ â†’ mÃ¡s creativo

---

#### PenalizaciÃ³n de repeticiÃ³n (repetition penalty)

Evita que el modelo repita frases o palabras.

- Valores altos = menos repeticiÃ³n  

Ideal para textos largos, cÃ³digo y redacciÃ³n formal.

---

#### Max tokens (longitud mÃ¡xima de respuesta)

Define cuÃ¡ntos tokens **puede generar como salida**.

Si max_tokens es muy pequeÃ±o â†’ respuestas truncadas.  
Si es grande â†’ textos mÃ¡s detallados.

---

### Resumen visual

| Concepto | Rol |
|---------|------|
| **Token** | Unidad mÃ­nima procesada |
| **Embedding** | RepresentaciÃ³n numÃ©rica del significado |
| **Ventana de contexto** | Memoria a corto plazo |
| **Temperatura** | Aleatoriedad |
| **Top-p / top-k** | Diversidad del texto |
| **max_tokens** | Longitud de salida |
| **ParÃ¡metros (weights)** | Capacidad del modelo |
| **Embedding dimension** | Profundidad conceptual |
| **Batch size** | Estabilidad durante entrenamiento |

---

## Frase clave:

> Los LLMs no â€œpiensanâ€: calculan probabilidades en un espacio matemÃ¡tico gigante lleno de significados.

---

## Tipos de LLMs (con ejemplos)

Los modelos actuales pueden clasificarse en **cuatro grandes categorÃ­as**, segÃºn su entrenamiento y capacidades.

---

### Modelos base (Base Models)

:::tiny
Entrenados con texto masivo, sin instrucciones humanas.  
Generan lenguaje, pero no siguen Ã³rdenes de manera natural.

**Ejemplos:**

- **GPT-3** (OpenAI, 2020)  
- **Llama 2 Base** (Meta, 2023)  
- **Mistral Base 7B** (Mistral AI, 2023)  
- **Gemma Base** (Google, 2024)  
- **Falcon 40B Base** (Technology Innovation Institute)

**Uso tÃ­pico:** pre-entrenamiento, fine-tuning, tareas no conversacionales.
:::

---

### Modelos Instruct (afinados para seguir instrucciones)

:::tiny
Entrenados con **RLHF** + **datasets de instrucciones**. Son los modelos â€œpara conversarâ€.

**Ejemplos:**

- **GPT-3.5 Turbo** (OpenAI)  
- **GPT-4, GPT-4o** (OpenAI)  
- **Claude 2, Claude 3 Sonnet / Opus** (Anthropic)  
- **Gemini Advanced (1.5 Pro / Ultra)** (Google)  
- **Llama 3 Instruct 8B / 70B** (Meta, 2024)  
- **Mistral Instruct 7B / 8x22B Mixtral** (Mistral AI)  
- **Command R / R+** (Cohere)  
- **Qwen 2 Instruct** (Alibaba)


**Uso tÃ­pico:** chat, preguntas/respuestas, anÃ¡lisis de texto, resÃºmenes, tareas empresariales.
:::

---

### Modelos multimodales (texto + imÃ¡genes + audio + video)

:::tiny
Pueden **ver, escuchar, interpretar y generar contenido** en mÃºltiples formatos.

**Ejemplos principales (2024â€“2025):**

- **GPT-4o** (OpenAI) â€” visiÃ³n + audio + razonamiento  
- **Gemini 1.5 Pro / Ultra** (Google) â€” video + imÃ¡genes + razonamiento largo  
- **Claude 3 Haiku / Sonnet / Opus** (Anthropic) â€” visiÃ³n y anÃ¡lisis profundo  
- **Llama 3 Vision** (Meta)  
- **Mistral NeMo Vision** (Mistral AI)  
- **Qwen2-VL** (Alibaba)  
- **Pika Labs** (generaciÃ³n de video)  
- **Runway Gen-2 / Gen-3** (video)

**Uso tÃ­pico:** interpretaciÃ³n de imÃ¡genes, resÃºmenes de PDFs, anÃ¡lisis de video, agentes con audio.
:::

---

### Modelos especializados (fine-tuning o entrenamiento especÃ­fico)
Optimizados para **una disciplina o tipo de tarea**.

##### Modelos para cÃ³digo

- **GPT-4o y GPT-4 Turbo (Code Interpreter / o1)**  
- **DeepSeek-Coder**  
- **StarCoder / StarCoder2**  
- **Code Llama**  
- **Phi-3 Mini para coding (Microsoft)**

---

#### Modelos para biologÃ­a / ciencias

- **Evo (OpenAI)** â€“ proteÃ­nas  
- **AlphaFold 2 / AlphaFold 3 (DeepMind)**  
- **ESM-2 (Meta)** â€“ secuencias proteicas

---

#### Modelos para agentes / razonamiento profundo

- **OpenAI o1 / o3**  
- **Gemini 1.5 Ultra (Chain-of-thought avanzado)**  
- **ReAct + modelos instruct** (framework)

---

#### Modelos para finanzas / negocios

- **BloombergGPT**  
- **FinGPT**  
- **Claude 3 Opus** (muy fuerte en anÃ¡lisis estructurado)  
- **Llama 3 + fine-tuning sectorial** (muy comÃºn en empresas)

---

#### Modelos para idiomas especÃ­ficos

- **Yi (China)**  
- **Qwen 2 (China)**  
- **Mistral Small (UE)**  
- **LLaMA 3 Spanish fine-tuned**

---

#### Modelos pequeÃ±os y rÃ¡pidos (edge)

- **Phi-3 (Microsoft)** â€” <4B parÃ¡metros  
- **LLaMA 3.1 8B**  
- **Mistral 7B**  
- **Gemma 2B / 7B**

**Uso tÃ­pico:** casos de uso especÃ­ficos, empresas que necesitan privacidad, modelos on-premise o en edge devices.

---

### BONUS: Modelos de imÃ¡genes, audio y video (no LLM pero complementarios)

- **DALLÂ·E 3** (OpenAI)  
- **Midjourney v6**  
- **Stable Diffusion XL / 3.0**  
- **Suno v3 (audio/mÃºsica)**  
- **ElevenLabs (voz)**  
- **Runway Gen-2 / Gen-3 (video)**

Permiten construir sistemas multimodales completos.

---

## CÃ³mo funciona: entrenamiento y prompting 

- Entrenamiento: El modelo aprende patrones desde grandes volÃºmenes de datos.

- Prompting: El usuario da una instrucciÃ³n â†’ el modelo genera contenido.

- Ejemplo: Prompt: *â€œEscribe un haiku sobre IA generativa.â€*

> Un prompt no es solo una pregunta: es un programa breve que guÃ­a el comportamiento del modelo.

---

# InterpretaciÃ³n de resultados de IA

## QuÃ© significa un â€œresultado confiableâ€

-   Un modelo **no entrega certezas**, entrega **probabilidades**
-   La confiabilidad depende de calidad de datos, validaciÃ³n del modelo, comparaciÃ³n entre predicciones y realidad
-   Ejemplo: *modelo de churn predice 80% â†’ no dice â€œrenunciarÃ¡â€, sino â€œprobabilidad alta de egresoâ€*

---

## Modelos discriminativos vs generativos

- **Discriminativos:** clasifican o predicen.  
- **Generativos:** crean contenido.

**AnalogÃ­a:**

- Discriminativo â†’ â€œÂ¿Es fraude o no?â€  
- Generativo â†’ â€œResume este caso de fraude.â€

---

## Aplicaciones de negocio 

- AtenciÃ³n al cliente  
- Desarrollo de software  
- DiseÃ±o de productos  
- DocumentaciÃ³n y reportes  
- AutomatizaciÃ³n de tareas repetitivas  
- Insights desde grandes volÃºmenes de texto

---

# Rol estratÃ©gico de la IA Generativa

## Â¿Reemplazo o colaboraciÃ³n? 

Caso: Kasparov vs Deep Blue  

```{r}
#| echo: false
#| message: false
#| warning: false
#| results: 'asis'

library(rvest)
library(dplyr)
library(glue)

url <- "https://www.chess.com/article/view/deep-blue-kasparov-chess"

page <- read_html(url)

title <- page %>%
  html_element("meta[property='og:title']") %>%
  html_attr("content")

description <- page %>%
  html_element("meta[property='og:description']") %>%
  html_attr("content")

cat(glue('
::: {{.callout-note}}
## {title}

{description}

[Leer nota completa]({url})
:::
'))
```

---

Caso: AlphaGo vs Lee

```{r}
#| echo: false
#| message: false
#| warning: false
#| results: 'asis'

library(rvest)
library(dplyr)
library(glue)

url <- "https://www.bbc.com/mundo/noticias/2016/03/160312_alphago_inteigencia_artificial_go_victoria_humano_men"

page <- read_html(url)

title <- page %>%
  html_element("meta[property='og:title']") %>%
  html_attr("content")

description <- page %>%
  html_element("meta[property='og:description']") %>%
  html_attr("content")

cat(glue('
::: {{.callout-note}}
## {title}

{description}

[Leer nota completa]({url})
:::
'))
```

---

Caso: OpenAI Five vs Team OG

```{r}
#| echo: false
#| message: false
#| warning: false
#| results: 'asis'

library(rvest)
library(dplyr)
library(glue)

url <- "https://www.iic.uam.es/innovacion/openai-five-juego-dota2/"

page <- read_html(url)

title <- page %>%
  html_element("meta[property='og:title']") %>%
  html_attr("content")

description <- page %>%
  html_element("meta[property='og:description']") %>%
  html_attr("content")

cat(glue('
::: {{.callout-note}}
## {title}

{description}

[Leer nota completa]({url})
:::
'))
```

ConclusiÃ³n:  
> La IA reemplaza tareas, no profesiones completas.

---

# ğŸš€ TransformaciÃ³n Organizacional con IA Generativa

La IA generativa no es solo una herramienta tecnolÃ³gica: es un catalizador de transformaciÃ³n organizacional que impacta procesos, personas, cultura, modelos de negocio y estrategias de datos.

---

## Â¿Por quÃ© la IA transforma organizaciones?

La IA generativa impulsa cambios profundos porque:

- Aumenta capacidades humanas.
- Automatiza tareas de alto costo cognitivo.
- Reduce tiempos entre idea â†’ prototipo â†’ ejecuciÃ³n.
- Abre nuevas posibilidades de productos y servicios.
- Permite rediseÃ±ar procesos completos.

**Idea clave:** La pregunta ya no es *â€œÂ¿podemos usar IA?â€*, sino **â€œÂ¿cÃ³mo reorganizamos nuestro trabajo para aprovechar IA de forma estratÃ©gica?â€**

---

## Alineamiento estratÃ©gico

La IA solo genera valor si estÃ¡ vinculada a metas del negocio.

### Principios:

:::tiny
- Conectar iniciativas de IA con KPIs reales (eficiencia, ingresos, retenciÃ³n, calidad).
- Priorizar casos de uso de alto impacto y bajo riesgo.
- Evitar pilotos aislados o experimentaciÃ³n sin direcciÃ³n.
- DiseÃ±ar una hoja de ruta que avance junto a la estrategia general de la organizaciÃ³n.

**Mensaje clave:** 

> La IA es una herramienta estratÃ©gica, no un juguete tecnolÃ³gico.

:::
---

## Cambio cultural y alfabetizaciÃ³n en IA

El mayor freno a la adopciÃ³n no es tÃ©cnico: es cultural.

### Cambios necesarios:

- Pasar de â€œtrabajo manualâ€ a â€œtrabajo aumentado por IAâ€.
- Fomentar una mentalidad de experimentaciÃ³n.
- Entrenar a los equipos en pensamiento crÃ­tico aplicado a IA.
- Normalizar el uso cotidiano de modelos generativos como un nuevo integrante del equipo.

---

### AlfabetizaciÃ³n en IA:

- Uso efectivo de prompts.
- Conocer lÃ­mites y riesgos del modelo.
- Evaluar la calidad de las respuestas.
- Integrar IA en tareas diarias sin perder criterio profesional.

---

## Gobernanza y gestiÃ³n del riesgo

La IA necesita un marco formal de gestiÃ³n responsable:

### Dimensiones de gobernanza:

- **Seguridad y privacidad de datos.**
- **MitigaciÃ³n de sesgos y fairness.**
- **Transparencia en procesos y decisiones.**
- **RegulaciÃ³n y compliance.**
- **PolÃ­ticas de uso responsable.**
- **EvaluaciÃ³n del impacto ecolÃ³gico asociado al cÃ³mputo.**

---

### Riesgos a gestionar:

- Alucinaciones.
- Sesgos inesperados.
- Ciberseguridad.
- Mal uso (deepfakes, automatizaciones sin control).
- Riesgos reputacionales.

---

## Impacto transversal en el negocio

La IA generativa afecta mÃºltiples Ã¡reas al mismo tiempo:

### Marketing

- PersonalizaciÃ³n.
- GeneraciÃ³n de contenido.
- SegmentaciÃ³n inteligente.

---

### Ventas

- RedacciÃ³n asistida.
- Score de oportunidades.
- Eficiencia comercial.

### Servicio al cliente

- Chatbots aumentados.
- ResÃºmenes de interacciones.
- DerivaciÃ³n inteligente.

---

### Operaciones / Supply Chain

- PredicciÃ³n.
- OptimizaciÃ³n.
- AutomatizaciÃ³n de tareas repetitivas.

### Recursos Humanos

- RedacciÃ³n de perfiles.
- CapacitaciÃ³n.
- EvaluaciÃ³n y retroalimentaciÃ³n mÃ¡s eficiente.

---

## IdentificaciÃ³n de oportunidades de IA

Las oportunidades pueden clasificarse en tres arquetipos:

### 1) **Augmentation**
La IA ejecuta parte de la tarea y el humano sigue controlando.

### 2) **Co-creation**
Humano + IA colaboran para producir un resultado final.

### 3) **Replacement**
La IA automatiza una tarea o proceso completo.

---

### Criterios para detectar oportunidades:
- Â¿La tarea es repetitiva?
- Â¿Consume tiempo excesivo?
- Â¿Implica generar contenido o analizar informaciÃ³n?
- Â¿La calidad del output se puede verificar fÃ¡cilmente?
- Â¿Hay potencial de mejorar costo, calidad o velocidad?

---

## Framework operativo para transformar con IA

### **1) Mapear procesos**

- Identificar tareas de alto costo cognitivo.
- Documentar pasos actuales.
- Detectar â€œIA-fitâ€ en microtareas especÃ­ficas.

---

### **2) Experimentar (â€œTrial & Iterateâ€)**

- Probar IA en tareas acotadas.
- Medir impacto real.
- Ajustar prompts, flujos y procesos.

### **3) Escalar**

- Entrenar mÃ¡s equipos.
- Integrar IA en sistemas existentes.
- Mantener mejora continua con mÃ©tricas claras.

---

## La IA redistribuye capacidades dentro de la organizaciÃ³n

:::tiny
La IA cambia **quÃ© tareas hacen las personas** y **cÃ³mo se distribuye el trabajo**:

- MÃ¡s tiempo para creatividad, anÃ¡lisis y decisiones.
- Menos tiempo en tareas repetitivas.
- Incremento de autonomÃ­a en roles operativos.
- ReorganizaciÃ³n de funciones tradicionales (marketing, finanzas, CX, TI).
- Emergencia de nuevos roles:
  - AI Product Owner  
  - Prompt Designer  
  - Model Steward  
  - AI Trainer  

:::

---

# ğŸ›¡ï¸ Ã‰tica, privacidad y riesgos en IA Generativa

La IA generativa introduce enormes oportunidades, pero tambiÃ©n dilemas Ã©ticos que deben gestionarse desde una mirada estratÃ©gica, responsable y centrada en las personas.

---

## Sesgos (Bias)

Los sesgos son uno de los riesgos mÃ¡s frecuentes y peligrosos en sistemas de IA. La IA aprende de datos histÃ³ricos que pueden contener desigualdades y, por tanto, puede amplificarlas.

---

### Por quÃ© ocurre

- Datos desbalanceados o incompletos.
- InclusiÃ³n directa o indirecta de variables sensibles.
- Modelos entrenados sin supervisiÃ³n Ã©tica.
- Falta de representatividad en los datos.

---

### CÃ³mo detectarlo

- Validar desempeÃ±o en mÃºltiples subgrupos.
- Tests de fairness (como demographic parity).
- AuditorÃ­as independientes.
- Monitoreo continuo.

---

### Estrategias de mitigaciÃ³n

- Remover variables sensibles.
- Rebalanceo o enriquecimiento de datasets.
- SupervisiÃ³n humana.
- Incluir fairness desde el diseÃ±o, no solo en el despliegue.

---

## Privacidad y el â€œprivacyâ€“personalization paradoxâ€

La personalizaciÃ³n aumenta la utilidad del sistema, pero genera tensiones con la privacidad. A mayor personalizaciÃ³n, mayor necesidad de datos personales.

---

### Riesgos

- ExposiciÃ³n de datos sensibles.
- Uso de informaciÃ³n sin consentimiento.
- Datos enviados a terceros sin control.
- IncorporaciÃ³n no autorizada de datos en el entrenamiento.

---

### Mitigaciones

- PolÃ­ticas de transparencia y consentimiento claras.
- MinimizaciÃ³n de datos.
- EncriptaciÃ³n, anonimizaciÃ³n y retenciÃ³n limitada.
- Cumplimiento normativo (GDPR, LGPD, Ley 19.628).

---

## Copyright y propiedad intelectual

La IA generativa plantea desafÃ­os legales y Ã©ticos en torno a la autorÃ­a y el uso de datos.

```{r}
#| echo: false
#| message: false
#| warning: false
#| results: 'asis'

library(rvest)
library(dplyr)
library(glue)

url <- "https://thelogic.co/news/cloudflare-ai-google-copyright"

page <- read_html(url)

title <- page %>%
  html_element("meta[property='og:title']") %>%
  html_attr("content")

description <- page %>%
  html_element("meta[property='og:description']") %>%
  html_attr("content")

cat(glue('
::: {{.callout-note}}
## {title}

{description}

[Leer nota completa]({url})
:::
'))
```

---

### Temas clave

- AutorÃ­a del contenido generado.
- Uso de materiales protegidos en entrenamiento.
- Derechos de imagen.
- Posible infracciÃ³n involuntaria por parte del usuario.

---

### Mitigaciones

- Claridad en los tÃ©rminos de uso del modelo.
- Modelos privados o on-premise para datos sensibles.
- GestiÃ³n responsable de datasets.
- DocumentaciÃ³n sobre fuentes y licencias.

---

## Transparencia, cajas negras y explicabilidad (XAI)

Muchos modelos de IA â€”especialmente los LLMsâ€” funcionan como **cajas negras**: sabemos quÃ© entra y quÃ© sale, pero no cÃ³mo se tomÃ³ la decisiÃ³n.

---

### Riesgos

- Falta de confianza del usuario final.
- Dificultad para auditar o corregir errores.
- Riesgo regulatorio.
- Falta de trazabilidad en decisiones crÃ­ticas.

---

### Soluciones

- **Explainable AI (XAI):**
  - **LIME (Local Interpretable Model-agnostic Explanations):** explicaciones locales simplificadas.
  - **SHAP (SHapley Additive exPlanations):** importancia de variables para determinar la predicciÃ³n.
- Uso de modelos interpretables cuando sea posible.
- DocumentaciÃ³n de supuestos, lÃ­mites y fuentes de datos.
- Transparencia en el ciclo de vida completo del modelo.

---

## Accountability (Responsabilidad humana)

La IA no es una excusa para evitar responsabilidad. Siempre debe haber un responsable humano por las decisiones donde la IA participa.

```{r}
#| echo: false
#| message: false
#| warning: false
#| results: 'asis'

library(rvest)
library(dplyr)
library(glue)

url <- "https://www.bbc.com/mundo/articles/cr7m1r027m9o"

page <- read_html(url)

title <- page %>%
  html_element("meta[property='og:title']") %>%
  html_attr("content")

description <- page %>%
  html_element("meta[property='og:description']") %>%
  html_attr("content")

cat(glue('
::: {{.callout-note}}
## {title}

{description}

[Leer nota completa]({url})
:::
'))
```

:::tiny

> OpenAI estima que mÃ¡s de un millÃ³n de sus 800 millones de usuarios semanales parecen expresar pensamientos suicidas

:::

---

### Problemas tÃ­picos

- Nadie asume responsabilidad por errores del modelo.
- â€œLo dijo la IAâ€ como racionalizaciÃ³n.
- AutomatizaciÃ³n excesiva sin supervisiÃ³n.
- Riesgo de confianza ciega en sistemas imperfectos.

---

### Mitigaciones

- Roles claros (equipo de datos, producto, legal).
- SupervisiÃ³n humana obligatoria (â€œhuman-in-the-loopâ€).
- Procedimientos de revisiÃ³n y auditorÃ­a.
- No delegar decisiones crÃ­ticas exclusivamente a la IA.

---

## Fairness y justicia algorÃ­tmica

El principio de **fairness** busca evitar discriminaciones directas o indirectas.

---

### Dimensiones tÃ­picas

- Raza y etnia.
- GÃ©nero.
- Edad.
- Nivel socioeconÃ³mico.
- Lenguaje, acento o paÃ­s de origen.
- Discapacidad.

---

### Ejemplos

- Modelos clÃ­nicos que priorizan ciertos subgrupos.
- Motores crediticios menos accesibles para minorÃ­as.
- Clasificadores de CVs entrenados con historiales sesgados.

---

## Riesgos emergentes

### Deepfakes y manipulaciÃ³n

- Contenido sintÃ©tico difÃ­cil de distinguir de lo real.
- Riesgo reputacional.
- ManipulaciÃ³n polÃ­tica o social.
- Fraudes mediante audio y video falsificado.

---

### MisinformaciÃ³n

- GeneraciÃ³n masiva de noticias falsas.
- Ataques de saturaciÃ³n informativa.
- ErosiÃ³n de la confianza pÃºblica.

---

### AutonomÃ­a y control humano

- Sistemas que actÃºan fuera de los lÃ­mites esperados.
- Dilema autonomÃ­aâ€“control.
- Proyectos con potencial riesgo fÃ­sico (autos autÃ³nomos, robots).

---

## Ethical AI by Design (Ã‰tica por diseÃ±o)

Los principios Ã©ticos deben integrarse desde la concepciÃ³n del proyecto, no como un â€œparcheâ€ posterior.

---

### Principios clave

- Definir objetivos explÃ­citos.
- Alinear con stakeholders relevantes.
- Gestionar datos con seguridad y criterios Ã©ticos.
- DiseÃ±ar con transparencia.
- Evaluar y mitigar sesgos desde el inicio.
- Abordar preocupaciones de impacto social.
- Iterar y monitorear continuamente.

---

### Beneficios

- Menor riesgo legal y reputacional.
- Mayor adopciÃ³n y confianza.
- Procesos de IA mÃ¡s robustos y auditables.
- Fomenta la innovaciÃ³n responsable.

---

## Â¿Por quÃ© importa todo esto?

- Aumenta la confianza del pÃºblico y los usuarios.  
- Reduce riesgos legales, operacionales y reputacionales.  
- Fomenta la innovaciÃ³n sostenible.  
- Permite aprovechar el potencial de la IA sin comprometer valores Ã©ticos.  
- Convierte la Ã©tica en una ventaja competitiva.  

> **La Ã©tica en IA no es solo buena prÃ¡ctica: es buena estrategia de negocios.**

---

# Referencias

::: tiny

- **Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Å., & Polosukhin, I.** (2017). *Attention Is All You Need.* Advances in Neural Information Processing Systems (NeurIPS).  
  Disponible en: <https://arxiv.org/abs/1706.03762>

- **OpenAI et al.** (2019). *Dota 2 with Large-Scale Deep Reinforcement Learning.* arXiv preprint arXiv:1912.06680.  
  Disponible en: <https://arxiv.org/pdf/1912.06680>
  
:::
